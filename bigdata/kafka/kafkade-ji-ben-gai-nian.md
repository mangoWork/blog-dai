#### Kafka基础知识

##### Kafka的优势


&nbsp;　　构建实时的流数据管道，可靠地获取系统和应用程序之间的数据。

&nbsp;　　构建实时流的应用程序，对数据流进行转换或反应。


##### Kafka所使用的基本术语：

**Topic**

> Kafka将消息分门别类，每一类的消息称之为一个主题\(Topic\)

**Producer**

> 发布消息的对象称之为生产者

**Consumer**

> 订阅消息并处理发布的消息的对象称之为消费者

**Broker**

> 已发布的消息保存在一组服务器中，称之为Kafka集群。集群中的每一个服务器都是一个代理\(Broker\)。消费者可以订阅一个或者多个主题\(Topic\),并从Broker拉数据，从而消费这些已发布的消息。

##### 主题和日志\(Topic和Log\)

&nbsp;　　Topic是发布的消息的类别。对于每一个Topic，Kafka集群维护着一个分区的log，如下图所示：

![](/bigdata/kafka/img/topic1.png)


&nbsp;　　每一个分区都是一个顺序的、不可变的消息队列，并且可以持续添加。分区中的消息都被分了一个序列号，称之为**偏移量\(offset\)**，在每隔分区中此偏移量都是唯一的。

&nbsp;　　Kafka集群保持所有的信息，直到它们过期，无论消息是否被消费了。实际上消费者所持有的仅有的元数据就是这个偏移量，也就是消费者在这个log中的位置。 这个偏移量由消费者控制：正常情况当消费者消费消息的时候，偏移量也线性的的增加。但是实际偏移量由消费者控制，消费者可以将偏移量重置为更老的一个偏移量，重新读取消息。并且一个消费者的操作不会影响其它消费者对此log的处理。

&nbsp;　　Kafka分区的目的：一是可以处理更多的消息，不受单台服务器的限制，Topic拥有更多分区也就意味着它可以不受限的处理更多的数据。第二，分区可以作为并行处理的单元。

##### 分布式
&nbsp;　　log的分区被分布到集群中的多个服务器上。每个服务器处理它分到的分区。 根据配置每个分区还可以复制到其它服务器作为备份容错。 每个分区有一个leader，零或多个follower。Leader处理此分区的所有的读写请求，而follower被动的复制数据。如果leader宕机，其它的一个follower会被推举为新的leader。 一台服务器可能同时是一个分区的leader，另一个分区的follower。 这样可以平衡负载，避免所有的请求都只让一台或者某几台服务器处理。

作者：半兽人
链接：http://orchome.com/5
来源：OrcHome
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

##### 生产者(Producers)
&nbsp;　　生产者往某个Topic上发布消息。生产者也负责选择发布到Topic上的哪一个分区。最简单的方式从分区列表中轮流选择。也可以根据某种算法依照权重选择分区。开发者负责如何选择分区的算法。


##### 消费者(Consumers)

&nbsp;　　通常来讲，消息模型可以分为两种， **队列**和**发布-订阅式**。 队列的处理方式是 一组消费者从服务器读取消息，一条消息只有其中的一个消费者来处理。在发布-订阅模型中，消息被广播给所有的消费者，接收到消息的消费者都可以处理此消息。
&nbsp;　　Kafka为这两种模型提供了单一的消费者抽象模型： **消费者组 （consumer group）**。 消费者用一个消费者组名标记自己。 一个发布在Topic上消息被分发给此消费者组中的一个消费者。 假如所有的消费者都在一个组中，那么这就变成了queue模型。 假如所有的消费者都在不同的组中，那么就完全变成了发布-订阅模型。 更通用的， 我们可以创建一些消费者组作为逻辑上的订阅者。每个组包含数目不等的消费者， 一个组内多个消费者可以用来扩展性能和容错。正如下图所示：
![](./img/kafkacluster.png)

&nbsp;　　2个kafka集群托管4个分区（P0-P3），2个消费者组，消费组A有2个消费者实例，消费组B有4个


作者：半兽人
链接：http://orchome.com/5
来源：OrcHome
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。

&nbsp;　　Kafka获取消息采用了一种分而治之的策略：**分区**。 因为Topic分区中消息只能由消费者组中的唯一一个消费者处理，所以消息肯定是按照先后顺序进行处理的。但是它也仅仅是保证Topic的一个分区顺序处理，不能保证跨分区的消息先后处理顺序。 所以，如果你想要顺序的处理Topic的所有消息，那就只提供一个分区。

##### Kafka的保证

&nbsp;　　生产者发送到一个特定的Topic的分区上，消息将会按照它们发送的顺序依次加入，也就是说，如果一个消息M1和M2使用相同的producer发送，M1先发送，那么M1将比M2的offset低，并且优先的出现在日志中。
&nbsp;　　消费者收到的消息也是此顺序。
&nbsp;　　如果一个Topic配置了复制因子（replication factor）为N， 那么可以允许N-1服务器宕机而不丢失任何已经提交（committed）的消息。


##### kafka的优
&nbsp;　　可扩展。Kafka集群可以透明的扩展，增加新的服务器进集群。
&nbsp;　　高性能。Kafka性能远超过传统的ActiveMQ、RabbitMQ等，Kafka支持Batch操作。
&nbsp;　　容错性。Kafka每个Partition数据会复制到几台服务器，当某个Broker失效时，Zookeeper将通知生产者和消费者从而使用其他的Broker。

##### kafka缺点：

&nbsp;　　重复消息。Kafka保证每条消息至少送达一次，虽然几率很小，但一条消息可能被送达多次。
&nbsp;　　消息乱序。Kafka某一个固定的Partition内部的消息是保证有序的，如果一个Topic有多个Partition，partition之间的消息送达不保证有序。
&nbsp;　　复杂性。Kafka需要Zookeeper的支持，Topic一般需要人工创建，部署和维护比一般MQ成本更高。


##### Kafka的使用场景

###### 消息

&nbsp;　　kafka更好的替换传统的消息系统，消息系统被用于各种场景（解耦数据生产者，缓存未处理的消息，等），与大多数消息系统比较，kafka有更好的吞吐量，内置分区，副本和故障转移，这有利于处理大规模的消息。
&nbsp;　　消息往往用于较低的吞吐量，但需要低的端到端延迟，并需要提供强大的耐用性的保证。在这一领域的kafka比得上传统的消息系统，如的ActiveMQ或RabbitMQ的。
###### 网上活动追踪

&nbsp;　　kafka原本的使用场景：用户的活动追踪，网站的活动（网页游览，搜索或其他用户的操作信息）发布到不同的话题中心，这些消息可实时处理，实时监测，也可加载到Hadoop或离线处理数据仓库。


###### 指标
&nbsp;　　kafka也常常用于监测数据。分布式应用程序生成的统计数据集中聚合。

###### 日志聚合
&nbsp;　　使用kafka代替一个日志聚合的解决方案。

###### 流处理
&nbsp;　　kafka消息处理包含多个阶段。其中原始输入数据是从kafka主题消费的，然后汇总，丰富，或者以其他的方式处理转化为新主题，例如，一个推荐新闻文章，文章内容可能从“articles”主题获取；然后进一步处理内容，得到一个处理后的新内容，最后推荐给用户。这种处理是基于单个主题的实时数据流。从0.10.0.0开始，轻量，但功能强大的流处理，就进行这样的数据处理了。

除了Kafka Streams，还有Apache Storm和Apache Samza可选择。

###### 事件采集
&nbsp;　　事件采集是一种应用程序的设计风格，其中状态的变化根据时间的顺序记录下来，kafka支持这种非常大的存储日志数据的场景。

###### 提交日志
&nbsp;　　kafka可以作为一种分布式的外部提交日志，日志帮助节点之间复制数据，并作为失败的节点来恢复数据重新同步，kafka的日志压缩功能很好的支持这种用法，这种用法类似于Apacha BookKeeper项目。
